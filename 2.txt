q1]

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv("HousePricePrediction.csv")

# Remove rows with any null values
data_cleaned = data.dropna()

# Select the feature and target variable
X = data_cleaned[['LotArea']]
y = data_cleaned['SalePrice']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Print results
print("Mean Squared Error:", rmse)
print("RÂ² Score:", r2)

plt.scatter(X_train, y_train, color='blue', label='Training Data')
plt.scatter(X_test, y_test, color='green', label='Test Data')
plt.plot(X_test, y_pred, color='red', label='Regression Line')
plt.xlabel('Size (square feet)')
plt.ylabel('Price (in $)')
plt.title('Simple Linear Regression - House Price Prediction')
plt.legend()
plt.show()
____________________________________________________
q2]

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Load the dataset
data = pd.read_csv('Wholesale customers data.csv')
print(data)

# Select features (annual spending on product categories and region)
features = ['Channel', 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']
X = data[features]
#y=target='Region'

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Agglomerative Clustering
agg_clustering = AgglomerativeClustering(n_clusters=4)  # You can choose the number of clusters
clusters = agg_clustering.fit_predict(X_scaled)
print(clusters)

# Add cluster labels to the original data
data['Cluster'] = clusters
# Visualization using Dendrogram
linkage_matrix = linkage(X_scaled, method='ward')
plt.figure(figsize=(10, 7))
dendrogram(linkage_matrix, labels=data.index)
plt.title('Dendrogram for Agglomerative Clustering')
plt.xlabel('Clients')
plt.ylabel('Eudelian Distance')
plt.show()

# Visualizing the clusters
plt.figure(figsize=(10, 7))
sns.scatterplot(x=data['Fresh'], y=data['Grocery'], hue=data['Cluster'], palette='viridis')
plt.title('Agglomerative Clustering of Wholesale Customers')
plt.xlabel('Annual Spending on Fresh Products')
plt.ylabel('Annual Spending on Grocery Products')
plt.legend(title='Cluster')
plt.show()

plt.figure(figsize=(10, 7))
sns.scatterplot(x=data['Milk'], y=data['Frozen'], hue=data['Cluster'], palette='viridis')
plt.title('Agglomerative Clustering of Wholesale Customers')
plt.xlabel('Annual Spending on Milk Products')
plt.ylabel('Annual Spending on Frozen Products')
plt.legend(title='Cluster')
plt.show()
